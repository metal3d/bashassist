# tAIrminal - give terminal commands some neurons

tAIrminal is a very simple "addon" to your command line that allows you to use
an AI (LLM) to generate terminal commands based on natural language or to ask AI
for general information.

By default, it is configured to use [Pollinations](https://pollinations.ai/) API, a free to use endpoint.
You can also use [ollama](https://ollama.com/) to run LLMs locally. For example, using
the very tiny `gemma3n:e2b` or `gemma3n:e4b` can be very effective. Of course, you can use any other model.

When the addon is active, you only have to type "#" (like writing a comment) and then your natural language question.
Then press `CTRL+x CTRL+o` (to be faster, keep `CTRL` pressed and then press `x` then `o`) to send the command to the AI.

If you want to ask a simple question, just use the "`ask`" command, for example:

```bash
ai "Who is Linux Torvalds?"
```

And wait a few seconds for the AI to generate the command. The command is ready to use.

<video src="https://github.com/user-attachments/assets/a2cdd8c2-4a13-43bc-adba-bac7f12e8e51" autoload autoplay controls loop></video>

## Requirements

You need 2 command line tools:

- [HTTPie](https://httpie.io/) (I currently don't support `curl` as Httpie helps a lot to send
  JSON data, URL encoding, etc.)
- [yq](https://github.com/mikefarah/yq) or [jq](https://jqlang.org/) command line. `yq` is preferred.

You may be able to install them with your package manager, for example:

```bash
# Fedora, Rocky Linux, AlmaLinux, etc.
dnf install httpie yq

# Ubuntu, Debian, etc.
apt install httpie yq

# pacman (Arch Linux, Manjaro, etc.)
pacman -S httpie yq
```

Then proceed to the test/installation section.

## Test

Before installing tAIrminal, you can test it directly in your terminal by running the following command:

```bash
source <(curl -s https://raw.githubusercontent.com/metal3d/tairminal/main/tairminal.sh)
```

Then type `#` followed by your question and press `CTRL+x CTRL+o` to see how it works.

## Installation

Copy the `tairminal.sh` script inside your `~/.bashrc.d` directory and ensure that it is sourced by your `~/.bashrc` file.

In many modern Linux distributions, this is already done by default. If not, you can add the following line to your `~/.bashrc`:

```bash
source ~/.bashrc.d/tairminal.sh
```

## Configuration

tAIrminal checks these files in this order:

- `$HOME/.local/share/tairminal/config`
- `$HOME/.config/tairminal/config`

You may add the following lines to your configuration file to customize the behavior of tAIrminal (given values are the default):

```bash
ENGINE="pollinations" # or "ollama"
SHORTCUT="\C-x\C-o" # the shortcut to send the command to the AI (readline format)
OLLAMA_MODEL="gemma3n:e2b" # or any other model you have installed
OLLAMA_URL="http://localhost:11434" # or any other URL where ollama is running
SHOW_INFO=true # display the information message in comment
# the system prompt for the AI, I recommend to keep it as is
SYSTEM="You must answer only with the raw Bash command that solves
the user's request. Do not include any explanations, comments, or formatting
(no backticks, no Markdown, no code block). Respond with the command only, as
if to paste it directly in the terminal. No line breaks, no quotes, no prefix,
no trailing punctuation."
```

You don't need to set all these variables, only the ones you want to change.

Also, you don't need to restart your terminal after changing the configuration file.

## Responsibilities

Patrice FERLET, main author of this tool, and any others contributors, **are not responsible for any damage
caused by the commands generated by the AI.**

You **must** check the command, and you are entirely responsible for the prompts you send to the AI.

In addition, you must ensure that the AI is not sending any command that could harm your system or data.
